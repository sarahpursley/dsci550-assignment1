{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Enron Dict Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email dict of sample with all sent Enron emails already created (see enron_corpus_download.py)\n",
    "\n",
    "#### OLIVIA CHANGE TO OUR FINAL DATA DIRECTORY#####\n",
    "\n",
    "import os\n",
    "from email.parser import Parser\n",
    "import json\n",
    "\n",
    "path = \"/Users/sarahpursley/Documents\"\n",
    "os.chdir(path)\n",
    "\n",
    "with open('enron_sample.json', 'r') as f:\n",
    "    email_dict = json.load(f)\n",
    "\n",
    "email_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the day of the week the email was sent out of enron data\n",
    "def get_days(dates):\n",
    "    day_dict = {}\n",
    "    \n",
    "    for d in dates:\n",
    "        d = d.replace(\",\", \"\").split(\" \")\n",
    "        day_of_week = d[0]\n",
    "        if day_of_week in day_dict:\n",
    "            day_dict[day_of_week] += 1\n",
    "        else:\n",
    "            day_dict[day_of_week] = 1\n",
    "    \n",
    "    return day_dict\n",
    "\n",
    "# get all the domains by stripping the to and from email fields and only keeping after the @ sign\n",
    "def get_domains(emails):\n",
    "    all_domains = []  \n",
    "\n",
    "    for email in emails:\n",
    "        if len(email.split()) > 1:\n",
    "            continue\n",
    "        else:\n",
    "            split = email.split(\"@\")\n",
    "            domain = split[1]\n",
    "        \n",
    "            if domain not in all_domains:\n",
    "                all_domains.append(domain)\n",
    "\n",
    "    return all_domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Enron dates from email_dict['Date'] values\n",
    "dates = email_dict['Date']\n",
    "day_week = get_days(dates)    # use function to get dictioary of day of weeks\n",
    "\n",
    "df_day = pd.DataFrame.from_dict(day_week, orient= 'index', columns = ['Freq'])\n",
    "\n",
    "# sort freq in desc order to get most frequent to least frequent\n",
    "df_result = df_day.sort_values(['Freq'], ascending = False)\n",
    "# assign score from 0-6 to each day of week\n",
    "score = range(0, len(df_day['Freq']))\n",
    "\n",
    "df_result['Score'] = score\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if in valid_domains \n",
    "# proxy for a theoretical total email database - check if sender is legitimate\n",
    "domain_comb = email_dict['To'] + email_dict['From']\n",
    "valid_domains = get_domains(domain_comb)\n",
    "print(f\"Valid domains extracted: {len(valid_domains)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get content from dict and make copy\n",
    "content = email_dict['content']\n",
    "content2 = content.copy()\n",
    "\n",
    "# find lengths off all emails\n",
    "content_char = []\n",
    "for con in content2:\n",
    "    content_len = len(con.split())\n",
    "    if content_len != 0:\n",
    "        content_char.append(content_len)\n",
    "\n",
    "# find only the unique lengths \n",
    "content_char = list(set(content_char))\n",
    "print(f\"Length of unique email lengths: {len(content_char)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE SAME CAPITALIZATION RATIO FROM STYLOMETRICS\n",
    "# counts number of capital letters and periods in a string and returns the ratio\n",
    "\n",
    "def count_period_ratio(string):\n",
    "    \"\"\"Input is a string of article\"\"\"\n",
    "   # print(string)\n",
    "    period_cnt = 0\n",
    "    capital_cnt = 0\n",
    "    \n",
    "    for letter in string:\n",
    "        if letter == \".\":\n",
    "            period_cnt+=1\n",
    "        elif letter.isupper() == True:\n",
    "            capital_cnt += 1\n",
    "    \n",
    "    ratio=capital_cnt/period_cnt\n",
    "    return ratio\n",
    "\n",
    "content = email_dict['content']\n",
    "content_dict = {}\n",
    "i = 0\n",
    "\n",
    "for c in content:\n",
    "    content_dict[i] = [c, len(c.strip().lstrip())]\n",
    "    i += 1\n",
    "\n",
    "for key,value in content_dict.items():\n",
    "    try:\n",
    "        ratio = count_period_ratio(value[0].strip().lstrip())\n",
    "        content_dict[key].append(ratio)\n",
    "    except ZeroDivisionError:\n",
    "        content_dict[key].append(0)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratearray = content_dict.values()\n",
    "# create dataframe from enron email content, email content length, capitilization ratio, and normalized capitilization ratio\n",
    "df1= pd.DataFrame(ratearray)\n",
    "df1.columns=[\"enron_text\", \"content_len\", \"ratio\"]\n",
    "df1['norm_ratio'] = df1['ratio']/df1['content_len']\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# get average email length \n",
    "enron_ratios = df1.groupby(by=[\"content_len\"]).mean().to_dict()\n",
    "enron_avg_length = round(np.mean(content_char))\n",
    "\n",
    "# find closest email length in eron dataset\n",
    "def closest_val(num):\n",
    "    func = lambda content_char : abs(content_char - num)\n",
    "    closest = min(content_char, key = func)\n",
    "    if closest == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return closest\n",
    "\n",
    "# find if the exact email length exists in the eron dataset\n",
    "def same_val(num):\n",
    "    num1 = closest_val(num)\n",
    "    num2 = num1 in content_char\n",
    "    \n",
    "    if num2 == True:\n",
    "        return \"enron email exists with this length\"\n",
    "    else:\n",
    "        return \"enron email does not exist with this length\"\n",
    "\n",
    "# given the fraud length, use the enron cap ratios to pull the capitalization ratio for that enron file \n",
    "# for comparison\n",
    "def match_val(num):\n",
    "    normalized = enron_ratios['norm_ratio']\n",
    "    for key, val in normalized.items():\n",
    "        if key != None and num != None:\n",
    "            if key == num:\n",
    "                return val \n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "# match the day of the week for fraud time value        \n",
    "def match_dates(fraud_date_format):\n",
    "    \n",
    "    day_match = {\n",
    "        'Sun': 'Sunday',\n",
    "        'Mon': 'Monday',\n",
    "        'Tue': 'Tuesday',\n",
    "        'Wed': 'Wednesday',\n",
    "        'Thu': 'Thursday',\n",
    "        'Fri': 'Friday',\n",
    "        'Sat': 'Saturday'}\n",
    "    \n",
    "    fraud_date = fraud_date_format.rpartition('T')[0]\n",
    "    day_of_week = datetime.date(year,month,day)\n",
    "    full_day = day_of_week.strftime(\"%A\")\n",
    "    \n",
    "    #matched_day\n",
    "    for key,value in day_match.items():\n",
    "        if value == full_day:\n",
    "            return key \n",
    "\n",
    "# lookup in any domain from fraud data matches a domain in enron dataset\n",
    "def domain_lookup(domain_list,domain):\n",
    "    for vd in domain_list:\n",
    "        if domain == vd:\n",
    "            return 'found'\n",
    "        else:\n",
    "            return 'not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in final scores and valid domains\n",
    "score_list = df_result.to_dict()['Score']\n",
    "score_list[None] = None \n",
    "valid_domains = get_domains(domain_comb)\n",
    "\n",
    "# functions to match day of weeks together\n",
    "def match_dates(fraud_date_format):\n",
    "    \n",
    "    day_match = {\n",
    "        'Sun': 'Sunday',\n",
    "        'Mon': 'Monday',\n",
    "        'Tue': 'Tuesday',\n",
    "        'Wed': 'Wednesday',\n",
    "        'Thu': 'Thursday',\n",
    "        'Fri': 'Friday',\n",
    "        'Sat': 'Saturday'}\n",
    "    \n",
    "    fraud_date = fraud_date_format.rpartition('T')[0]\n",
    "    day_of_week = datetime.date(year,month,day)\n",
    "    full_day = day_of_week.strftime(\"%A\")\n",
    "    \n",
    "    #matched_day\n",
    "    for key,value in day_match.items():\n",
    "        if value == full_day:\n",
    "            return key \n",
    "\n",
    "# function to lookup an Enron domain \n",
    "def domain_lookup(domain_list,domain):\n",
    "    for vd in domain_list:\n",
    "        if domain == vd:\n",
    "            return 'found'\n",
    "        else:\n",
    "            return 'not found'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in fraud messages\n",
    "#### Insert new features into final JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fraud dataset\n",
    "### OLIVE CHANGE THIS TO THE PATH ####\n",
    "path_file = ''\n",
    "f = open(path_file) \n",
    "messages = json.load(f) \n",
    "f.close()\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    content = message[\"X-TIKA:content\"].lstrip().strip()\n",
    "    closest_enron_value = closest_val(len(content.split()))\n",
    "    closest_enron_ratio = match_val(closest_enron_value)\n",
    "    length_exists = same_val(closest_enron_value)\n",
    "    \n",
    "    try:\n",
    "        author_email = message['Message:From-Email']\n",
    "        domain = author_email.split('@')[-1]\n",
    "        domain_match = domain_lookup(valid_domains, domain)\n",
    "    except KeyError:\n",
    "        author_email = None\n",
    "\n",
    "    \n",
    "    try:\n",
    "        date_created = match_dates(message['Creation-Date'])\n",
    "        score_created = score_list[date_created]\n",
    "    except KeyError:\n",
    "        date_created = None\n",
    "        score_created = None\n",
    "        \n",
    "    try: \n",
    "        date_sent = message['MboxParser-from'].strip(\"  \").split(\" \")[2]\n",
    "        score_sent = score_list[date_sent]\n",
    "    except KeyError:\n",
    "        date_sent = None\n",
    "        score_sent = None\n",
    "        \n",
    "    message['fraud msg characters'] = len(content.split())\n",
    "    message['enron avg. msg characters'] = int(enron_avg_length)\n",
    "    message['enron find similar characters'] = length_exists\n",
    "    message['enron closest capitilization ratio'] = closest_enron_ratio\n",
    "    message['enron capitilzation ratio difference'] = message['capitalization_ratio'] - closest_enron_ratio\n",
    "    message['enron domain lookup'] = (domain, domain_match)\n",
    "    message['enron day created score'] = (date_created, score_created)\n",
    "    message['enron day sent score'] = (date_sent, score_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
